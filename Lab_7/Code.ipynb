{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "myFV0MXIo8HB"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from keras import layers\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tqdm import tqdm\r\n",
        "!pip install progiter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5HuNwZ8cLJa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRRcakYMcMDc"
      },
      "source": [
        "# Linear regression with automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiB9YaH4-7eh"
      },
      "source": [
        "data_points = 10\r\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck2s3dlXpnzw",
        "outputId": "8debdabb-0747-49ce-98bb-4a07ce89b342"
      },
      "source": [
        "random.seed(4)\r\n",
        "y = [float(random.randint(20,50)) for i in range(data_points)]\r\n",
        "x = [float(y[i]-2 - random.randint(0, 15)) for i in range(data_points)]\r\n",
        "print(y)\r\n",
        "print(x)\r\n",
        "y_copy = y\r\n",
        "x_copy  = x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[27.0, 29.0, 23.0, 43.0, 32.0, 35.0, 24.0, 22.0, 22.0, 20.0]\n",
            "[13.0, 18.0, 20.0, 34.0, 19.0, 25.0, 17.0, 17.0, 12.0, 12.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxiap5JxrsF2"
      },
      "source": [
        "class MyModel(keras.Model):\r\n",
        "  def __init__(self, x, y, lr=0.01, optimizer = keras.optimizers.Adam):\r\n",
        "    super(MyModel, self).__init__()\r\n",
        "    self.x = tf.Variable(x, trainable=False) # if second argument ignored (which I did in my first try) model also \r\n",
        "                                             # \"optimizes\" original data points\r\n",
        "    self.y = tf.Variable(y,trainable=False)\r\n",
        "    self.optimizer = optimizer(lr=lr)\r\n",
        "    self.a = tf.Variable(1.)\r\n",
        "    self.b = tf.Variable(1.)\r\n",
        "    self.step = 1\r\n",
        "\r\n",
        "  def MSE(self, true, pred):\r\n",
        "    return tf.reduce_mean(tf.square(pred-true))\r\n",
        "  \r\n",
        "  def predict (self, x, a, b):\r\n",
        "    return a * self.x + b\r\n",
        "  \r\n",
        "  \r\n",
        "\r\n",
        "  def train_step(self):\r\n",
        "    with tf.GradientTape() as GT:\r\n",
        "      #GT.watch(self.a)\r\n",
        "      #GT.watch(self.b)\r\n",
        "      y_pred = self.predict(self.x, self.a, self.b)\r\n",
        "      loss = self.MSE(self.y, y_pred)\r\n",
        "    \r\n",
        "\r\n",
        "    gradients = GT.gradient(loss, self.trainable_variables)\r\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n",
        "\r\n",
        "    if(self.step%5==0):\r\n",
        "      print(\"\\nEpoch: \", self.step)\r\n",
        "      print(\"\\nLoss: \", float(loss))\r\n",
        "      print(\"\\nParameters: a:{:6.5f} b:{:6.5f}\".format(float(self.a),float(self.b)))\r\n",
        "      #print(self.trainable_variables)\r\n",
        "    \r\n",
        "    self.step+=1\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QHzZWXxsXF7"
      },
      "source": [
        "mod = MyModel(x,y, 0.5)\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "  mod.train_step()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdSwXyjpRceK"
      },
      "source": [
        "test=x*mod.a + mod.b\r\n",
        "print(test.numpy())\r\n",
        "print(y_copy)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtOJdsw1Jq2v"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# Tensorflow implementation of GAN\r\n",
        "\r\n",
        "**Thumps up rules derived from original DCGAN paper**\r\n",
        "\r\n",
        "1. Use Strided Convolutions in discriminator instead of pooling (e.g. maxpooling). Similarly, fractional stride (deconvolutional layers) can be used in the generator for upsampling.\r\n",
        "2. No fully connected layers\r\n",
        "3. Use batch normalization (except in the output of the generator and input to the discriminator).\r\n",
        "4. For generators ReLU is preferred except output layer (Tanh), for discriminator LeakyReLU (with slope of 0.2) is better choice\r\n",
        "5. Adam optimizer is better choice with lr  = 0.0002 and beta1 = 0.5\r\n",
        "\r\n",
        "For additional tips : https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IB3F9NWCeAS"
      },
      "source": [
        "(x_train, y_train),  (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\r\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\r\n",
        "x_train, x_test = (x_train-127.5)/127.5 , (x_test-127.5)/127.5\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx75-oslDLZS"
      },
      "source": [
        "def make_generator():\r\n",
        "  model = keras.Sequential(name=\"Generator\")\r\n",
        "  model.add(layers.Dense(7*7*256, input_shape=[100,]))\r\n",
        "  model.add(layers.BatchNormalization())\r\n",
        "  model.add(layers.LeakyReLU())\r\n",
        "  model.add(layers.Reshape((7, 7, 256)))\r\n",
        "  print(\"0: \", model.output_shape) # for debugging purposes\r\n",
        "  \r\n",
        "  #assert model.output_shape == (None, 7, 7, 256) # (batch size, h, w, channels)\r\n",
        "  \r\n",
        "  model.add(layers.UpSampling2D())\r\n",
        "  print(\"1: \", model.output_shape)\r\n",
        "  model.add(layers.Conv2D(128, kernel_size=3, padding=\"same\"))\r\n",
        "  print(\"2: \", model.output_shape)\r\n",
        "  model.add(layers.BatchNormalization(momentum=0.8))\r\n",
        "  model.add(layers.Activation(\"relu\"))\r\n",
        "  print(\"3: \", model.output_shape)\r\n",
        "  model.add(layers.UpSampling2D())\r\n",
        "  print(\"4: \", model.output_shape)\r\n",
        "  model.add(layers.Conv2D(64, kernel_size=3, padding=\"same\"))\r\n",
        "  print(\"5: \", model.output_shape)\r\n",
        "  model.add(layers.BatchNormalization(momentum=0.8))\r\n",
        "  model.add(layers.Activation(\"relu\"))\r\n",
        "  model.add(layers.Conv2D(1, kernel_size=3, padding=\"same\"))\r\n",
        "  #No batch normalization according to the rule\r\n",
        "  print(\"6: \", model.output_shape)\r\n",
        "  model.add(layers.Activation(\"tanh\"))\r\n",
        "  return model\r\n",
        "\r\n",
        "generator = make_generator()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "DlcNb3iTPuxr",
        "outputId": "995b351f-da19-4d20-ef49-991acdbf3c2a"
      },
      "source": [
        "random.seed(42)\r\n",
        "first_noise = tf.random.normal([1, 100])\r\n",
        "\r\n",
        "generated_image = generator(first_noise, training=False)\r\n",
        "#generated_image.numpy\r\n",
        "\r\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray') # first dimension is the batch size, last is channel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f76cb2d1710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73Pt9qbVDP-H"
      },
      "source": [
        "def make_discriminator():\r\n",
        "  model = keras.Sequential(name=\"Discriminator\")\r\n",
        "  model.add(layers.Conv2D(64, kernel_size=5, strides=(2,2), padding='same', input_shape=[28,28,1]))\r\n",
        "  print(model.output_shape)\r\n",
        "  model.add(layers.LeakyReLU(0.2))\r\n",
        "  model.add(layers.Dropout(0.25))\r\n",
        "  model.add(layers.Conv2D(128, kernel_size=5, strides=(2,2), padding='same'))\r\n",
        "  model.add(layers.BatchNormalization(momentum=0.8))\r\n",
        "  model.add(layers.LeakyReLU(0.2))\r\n",
        "  model.add(layers.Dropout(0.25))\r\n",
        "  model.add(layers.Conv2D(256, kernel_size=5, strides=(1,1), padding='same'))\r\n",
        "  model.add(layers.BatchNormalization(momentum=0.8))\r\n",
        "  model.add(layers.LeakyReLU(0.2))\r\n",
        "  model.add(layers.Dropout(0.25))\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(1))\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJlpe_e4JVl6",
        "outputId": "e1b6ad25-36b0-4fca-ee45-52492247e1d8"
      },
      "source": [
        "discriminator = make_discriminator()\r\n",
        "print(discriminator.summary())\r\n",
        "#output = discriminator(generated_image, training=False)\r\n",
        "#print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 14, 14, 64)\n",
            "Model: \"Discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 7, 7, 256)         819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 12545     \n",
            "=================================================================\n",
            "Total params: 1,040,129\n",
            "Trainable params: 1,039,361\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBNCTKdSWiK0"
      },
      "source": [
        "\r\n",
        "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "\r\n",
        "def discriminator_loss(real_output, fake_output):\r\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\r\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\r\n",
        "  total_loss = real_loss + fake_loss\r\n",
        "  return total_loss\r\n",
        "\r\n",
        "def generator_loss(fake_output):\r\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkPPwZfHXNpl"
      },
      "source": [
        "generator_optimizer = keras.optimizers.Adam(2e-4, 0.5)\r\n",
        "discriminator_optimizer = keras.optimizers.Adam(2e-4, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEZgIpfuU34l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f4e79a-2ecb-4eb4-9958-b35eb9b17ea1"
      },
      "source": [
        "import math\r\n",
        "batch_size = 256\r\n",
        "noise_dim = 100\r\n",
        "epochs = 30\r\n",
        "math.ceil(len(x_train)/batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5riESPGMKeZ6"
      },
      "source": [
        "class DCGAN(keras.Model):\r\n",
        "  def __init__(self, generator, discriminator):\r\n",
        "    super(DCGAN, self).__init__()\r\n",
        "    self.generator = generator\r\n",
        "    self.discriminator = discriminator\r\n",
        "    self.step = 0\r\n",
        "\r\n",
        "  def train_step(self, images):\r\n",
        "    noise = tf.random.normal([batch_size, noise_dim])\r\n",
        "    \r\n",
        "    with tf.GradientTape() as gt_disc, tf.GradientTape() as gt_gen:\r\n",
        "      \r\n",
        "      generated_images = self.generator(noise, training=True)\r\n",
        "\r\n",
        "      real_output = self.discriminator(images, training=True)\r\n",
        "      fake_output = self.discriminator(generated_images, training=True)\r\n",
        "\r\n",
        "      gen_loss = generator_loss(fake_output)\r\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\r\n",
        "\r\n",
        "      if(self.step % math.ceil(len(x_train)/batch_size) == 0):\r\n",
        "        print(\"\\n\\nGenerator Loss: {}\\nDisciminator Loss: {}\\n\".format(gen_loss, disc_loss))\r\n",
        "      self.step+=1\r\n",
        "      \r\n",
        "\r\n",
        "    gradients_of_generator = gt_gen.gradient(gen_loss, self.generator.trainable_variables)\r\n",
        "    gradients_of_discriminator = gt_disc.gradient(disc_loss, self.discriminator.trainable_variables)\r\n",
        "\r\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\r\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  \r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti6OTNH31F10"
      },
      "source": [
        "from progiter import ProgIter\r\n",
        "generated_images = list()\r\n",
        "#too slow training process\r\n",
        "data = tf.data.Dataset.from_tensor_slices(x_train).shuffle(60000).batch(batch_size)\r\n",
        "gan_model = DCGAN(generator, discriminator)\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "  print(\"\\nStarting epoch {}\".format(epoch+1))\r\n",
        "  \r\n",
        "  \r\n",
        "  for batch in ProgIter(data):\r\n",
        "    gan_model.train_step(batch)\r\n",
        "  \r\n",
        "  result = gan_model.generator(first_noise, training=False)\r\n",
        "  result = (result[0,:,:,0]*127.5)+127.5\r\n",
        "  generated_images.append(result)\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GhJWzYIiLll"
      },
      "source": [
        "generated_images = np.array(generated_images)\r\n",
        "generated_images.shape\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(12,10))\r\n",
        "\r\n",
        "for i in range(generated_images.shape[0]):\r\n",
        "  plt.subplot(6,5,i+1)\r\n",
        "  #plt.set_title('Buyuk basari')\r\n",
        "  plt.imshow(generated_images[i,:,:], cmap='gray')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
